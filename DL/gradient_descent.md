minimize an Objective function (error function)

types of optimization algorithms
1. First order optimization algorithms
Gradient descent  가 대표적
 parameter 에 대한  gradient 를 사용해서 최소화.
First order Derivative basically give us a line which is Tangential to a point on its Error Surface
a gradient is calculated using Partial Derivatives
2. second order optimization algorithms
use the second order derivative 
 tells us whether the first derivative is increasing or decreasing which hints at the function’s curvature
 a quadratic surface which touches the curvature of the Error Surface.
 계산 비용은 높지만, curvature of Surface.


https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f
